{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Example\n",
    "\n",
    "quick walkthrough of the Documentation's Example of Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('mytree').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import (DecisionTreeClassifier, \n",
    "                                       RandomForestClassifier, \n",
    "                                       GBTClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = spark.read.format('libsvm').load('sample_libsvm_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|              label|\n",
      "+-------+-------------------+\n",
      "|  count|                100|\n",
      "|   mean|               0.57|\n",
      "| stddev|0.49756985195624287|\n",
      "|    min|                0.0|\n",
      "|    max|                1.0|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees\n",
    "\n",
    "Gradient-boosted trees (GBTs) are a popular classification and regression method using ensembles of decision trees. More information about the spark.ml implementation can be found further in the section on [GBTs.](http://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-trees-gbts). For more information on the algorithm itself, please see the [spark.mllib documentation on GBTs.](http://spark.apache.org/docs/latest/mllib-ensembles.html#gradient-boosted-trees-gbts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(featuresCol='features', labelCol='label', predictionCol='prediction')\n",
    "rfc = RandomForestClassifier(featuresCol='features', labelCol='label', predictionCol='prediction', numTrees=100)\n",
    "gbc = GBTClassifier(featuresCol='features', labelCol='label', predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "gbc_model = gbc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc_preds = dtc_model.transform(test_data)\n",
    "rfc_preds = rfc_model.transform(test_data)\n",
    "gbc_preds = gbc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc_preds.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9618338650596716"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('DTC Accuracy: ')\n",
    "acc_eval.evaluate(dtc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rfc Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Rfc Accuracy: ')\n",
    "acc_eval.evaluate(rfc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9618338650596716"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('GBC Accuracy: ')\n",
    "acc_eval.evaluate(gbc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(692, {119: 0.0005, 157: 0.0017, 176: 0.0005, 178: 0.0005, 180: 0.0012, 184: 0.0005, 186: 0.0005, 207: 0.0053, 218: 0.0006, 234: 0.0097, 237: 0.0005, 240: 0.0015, 242: 0.0007, 243: 0.0005, 244: 0.0001, 260: 0.0005, 262: 0.0111, 263: 0.0129, 266: 0.0005, 272: 0.0089, 273: 0.0072, 274: 0.0078, 290: 0.0075, 295: 0.0069, 299: 0.0026, 301: 0.0024, 302: 0.0006, 317: 0.0143, 318: 0.0071, 322: 0.0001, 323: 0.0145, 324: 0.0011, 326: 0.0013, 331: 0.0006, 344: 0.0075, 350: 0.0659, 351: 0.0188, 352: 0.0005, 356: 0.0078, 372: 0.001, 373: 0.0092, 374: 0.0079, 375: 0.0015, 377: 0.0247, 378: 0.0325, 380: 0.0016, 384: 0.0071, 385: 0.0055, 387: 0.0014, 398: 0.002, 399: 0.0024, 400: 0.0108, 401: 0.0026, 405: 0.0605, 406: 0.0184, 407: 0.0225, 408: 0.006, 409: 0.0009, 427: 0.0118, 428: 0.0076, 429: 0.0101, 432: 0.0016, 433: 0.0637, 434: 0.0137, 435: 0.01, 440: 0.0109, 442: 0.0005, 455: 0.0243, 456: 0.0433, 457: 0.001, 458: 0.0005, 460: 0.0164, 461: 0.0385, 462: 0.0186, 463: 0.0169, 464: 0.001, 466: 0.0006, 470: 0.0008, 471: 0.0022, 472: 0.0005, 483: 0.0166, 488: 0.0079, 489: 0.0631, 490: 0.0216, 495: 0.0011, 498: 0.0005, 510: 0.0114, 511: 0.0106, 512: 0.0106, 513: 0.0021, 516: 0.0003, 517: 0.032, 518: 0.0048, 519: 0.0005, 520: 0.0008, 521: 0.0009, 522: 0.0013, 523: 0.0022, 526: 0.002, 538: 0.0005, 539: 0.009, 540: 0.0175, 541: 0.0033, 544: 0.0069, 545: 0.0006, 549: 0.0006, 566: 0.0073, 567: 0.0063, 596: 0.0006, 608: 0.0013, 626: 0.0017, 627: 0.0005, 628: 0.0009, 629: 0.0005, 631: 0.0008, 632: 0.0006, 637: 0.0005, 651: 0.0005, 656: 0.0004, 657: 0.0037})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|(692,[122,123,124...|\n",
      "|       0.0|  0.0|(692,[123,124,125...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "my_data = spark.read.format('libsvm').load('sample_libsvm_data.txt')\n",
    "\n",
    "# Split data\n",
    "train_Data, test_Data = my_data.randomSplit([0.7,0.3])\n",
    "\n",
    "# Train a GBT model\n",
    "gbt = GBTClassifier(labelCol='label', featuresCol='features', maxIter=10)\n",
    "\n",
    "# Train model, this also runs the indexers\n",
    "model = gbt.fit(train_Data)\n",
    "\n",
    "# Make a prediction\n",
    "predictions = model.transform(test_Data)\n",
    "\n",
    "# Select example row to display\n",
    "predictions.select(['prediction', 'label', 'features']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.037037\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and comput test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print('Test Error = %g' % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So this data isn't really realistic enough to really judge to effectiveness of GBT models, this data makes it seem like they are perfection, instead of just an improvement on normal Random Forests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
